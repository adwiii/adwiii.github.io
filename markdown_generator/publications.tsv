pub_date	title	venue	excerpt	citation	url_slug	paper_url	bibtex	image	github
2019-6-24	Faster Biclique Mining in Near-Bipartite Graphs	International Symposium on Experimental Algorithms	Identifying dense bipartite subgraphs is a common graph data mining task. Many applications focus on the enumeration of all maximal bicliques (MBs), though sometimes the stricter variant of maximal induced bicliques (MIBs) is of interest. Recent work of Kloster et al. introduced a MIB-enumeration approach designed for ‚Äúnear-bipartite‚Äù graphs, where the runtime is parameterized by the size k of an odd cycle transversal (OCT), a vertex set whose deletion results in a bipartite graph. Their algorithm was shown to outperform the previously best known algorithm even when k was logarithmic in <code>|V|</code>. In this paper, we introduce two new algorithms optimized for near-bipartite graphs - one which enumerates MIBs in time <code>O(M<sub>I</sub>|V||E|k)</code>, and another based on the approach of Alexe et al. which enumerates MBs in time <code>O(M<sub>B</sub>|V||E|k)</code>, where <code>M<sub>I</sub></code> and <code>M<sub>B</sub></code> denote the number of MIBs and MBs in the graph, respectively. We implement all of our algorithms in open-source C++ code and experimentally verify that the OCT-based approaches are faster in practice than the previously existing algorithms on graphs with a wide variety of sizes, densities, and OCT decompositions.	"Sullivan, Blair D., Andrew van der Poel, and Trey Woodlief. ""Faster Biclique Mining in Near-Bipartite Graphs."" <i>International Symposium on Experimental Algorithms</i>. Springer, Cham, 2019."	faster-biclique-mining	https://link.springer.com/chapter/10.1007/978-3-030-34029-2_28	@inproceedings{sullivan2019faster,  title={Faster Biclique Mining in Near-Bipartite Graphs},  author={Sullivan, Blair D and Poel, Andrew van der and Woodlief, Trey},  booktitle={International Symposium on Experimental Algorithms},  pages={424--453},  year={2019},  organization={Springer}}
2021-5-30	Fuzzing Mobile Robot Environments for Fast Automated Crash Detection	2021 IEEE International Conference on Robotics and Automation (ICRA)	Testing mobile robots is difficult and expensive, and many faults go undetected. In this work we explore whether fuzzing, an automated test input generation technique, can more quickly find failure inducing inputs in mobile robots. We developed a simple fuzzing adaptation, BASE-FUZZ, and one specialized for fuzzing mobile robots, PHYS-FUZZ. PHYS-FUZZ is unique in that it accounts for physical attributes such as the robot dimensions, estimated trajectories, and time to impact measures to guide the test input generation process. The results of evaluating PHYS-FUZZ suggest that it has the potential to speed up the discovery of input scenarios that reveal failures, finding 56.5% more than uniform random input selection and 7.0% more than BASE-FUZZ during 7 days of testing.	"T. Woodlief, S. Elbaum and K. Sullivan, ""Fuzzing Mobile Robot Environments for Fast Automated Crash Detection,"" <i>2021 IEEE International Conference on Robotics and Automation (ICRA)</i>, 2021, pp. 5417-5423, doi: 10.1109/ICRA48506.2021.9561627."	fuzzing-mobile-robot-environments	https://ieeexplore.ieee.org/abstract/document/9561627	@inproceedings{woodlief2021fuzzing,  title={Fuzzing Mobile Robot Environments for Fast Automated Crash Detection},  author={Woodlief, Trey and Elbaum, Sebastian and Sullivan, Kevin},  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},  pages={5417--5423},  year={2021},  organization={IEEE}}	/images/icra_fuzzing.png
2022-5-29	Preparing Software Engineers to Develop Robot Systems	44th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET ‚Äô22)	Robotics is a rapidly expanding field that needs software engineers. Most of our undergraduates, however, are not equipped to manage the unique challenges associated with the development of software for modern robots. In this work we introduce a course we have designed and delivered to better prepare students to develop software for robot systems. The course is unique in that: it emphasizes the distinctive challenges of software development for robots paired with the software engineering techniques that may help manage those challenges, it provides many opportunities for experiential learning across the robotics and software engineering interface, and it lowers the barriers for learning how to build such systems. In this work we describe the principles and innovations of the course, its content and delivery, and finish with the lessons we have learned"	Carl Hildebrandt, Meriel von Stein, Trey Woodlief, and Sebastian Elbaum. 2022. Preparing Software Engineers to Develop Robot Systems. In 44th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET ‚Äô22), May 21‚Äì29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3510456.3514161	preparing-software-engineers-to-develop-robot-systems	https://hildebrandt-carl.com/files/2022-05-21-ICSE-SERobotics.pdf	@INPROCEEDINGS{hildebrandt2022preparing,  author={Hildebrandt, Carl and Stein, Meriel von and Woodlief, Trey and Elbaum, Sebastian},  booktitle={2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)},   title={Preparing Software Engineers to Develop Robot Systems}, year={2022},  pages={205-216},  doi={10.1145/3510456.3514161}}	/images/cs4501_fall22_project.gif
2022-5-29	Semantic Image Fuzzing of AI Perception Systems	44th International Conference on Software Engineering (ICSE 2022)	Perception systems enable autonomous systems to interpret raw sensor readings of the physical world. Testing of perception systems aims to reveal misinterpretations that could cause system failures. Current testing methods, however, are inadequate. The cost of human interpretation and annotation of real-world input data is high, so manual test suites tend to be small. The simulation-reality gap reduces the validity of test results based on simulated worlds. And methods for synthesizing test inputs do not provide corresponding expected interpretations. To address these limitations, we developed ùë†ùëíùëöùëÜùëíùëõùë†ùêπùë¢ùëßùëß, a new approach to fuzz testing of perception systems based on semantic mutation of test cases that pair real-world sensor readings with their ground-truth interpretations. We implemented our approach to assess its feasibility and potential to improve software testing for perception systems. We used it to generate 150,000 semantically mutated image inputs for five state-of-the-art perception systems. We found that it synthesized tests with novel and subjectively realistic image inputs, and that it discovered inputs that revealed significant inconsistencies between the specified and computed interpretations. We also found that it produced such test cases at a cost that was very low compared to that of manual semantic annotation of real-world images.	Trey Woodlief, Sebastian Elbaum, and Kevin Sullivan. 2022. Semantic Image Fuzzing of AI Perception Systems. In 44th International Conference on Software Engineering (ICSE ‚Äô22), May 21‚Äì29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3510003.3510212	semantic-image-fuzzing	https://github.com/less-lab-uva/perception_fuzzing/blob/main/Semantic%20Image%20Fuzzing%20of%20AI%20Perception%20Systems.pdf	@inproceedings{woodlief2022semantic,  title={Semantic image fuzzing of AI perception systems},  author={Woodlief, Trey and Elbaum, Sebastian and Sullivan, Kevin},  booktitle={Proceedings of the 44th International Conference on Software Engineering}, pages={1958--1969}, year={2022}}	/images/semSensFuzz.png	https://github.com/less-lab-uva/perception_fuzzing
2023-5-20	Generating Realistic and Diverse Tests for LiDAR-Based Perception Systems	45th International Conference on Software Engineering (ICSE 2023)	Autonomous systems rely on a perception component to interpret their  surroundings, and when   misinterpretations occur, they can and have led to serious and fatal system-level failures. Yet, existing methods for testing  perception software remain limited in both their capacity to efficiently generate test data that translates to real-world performance and in their diversity to capture the long tail of rare but safety-critical scenarios. These limitations are particularly evident for  perception systems based on LiDAR sensors, which have emerged as a crucial component in modern autonomous systems due to their ability to provide a 3D scan of the world and operate in all lighting conditions. To address these limitations, we introduce a novel approach for testing LiDAR-based perception systems by leveraging existing real-world data as a basis to generate realistic and diverse test cases through mutations that preserve realism invariants while generating inputs rarely found in existing data sets, and automatically crafting   oracles that identify potentially safety-critical issues in perception performance. We implemented our approach to assess its ability to identify perception failures, generating over 50,000 test inputs for five state-of-the-art LiDAR-based perception systems. We found that it efficiently generated test cases that  yield errors in perception that could result in real consequences if these systems were deployed and does so at a low rate of false positives.	Coming soon	semantic-lidar-fuzzing	https://github.com/less-lab-uva/semLidarFuzz/blob/master/Generating%20Realistic%20and%20Diverse%20Tests%20for%20LiDAR-Based%20Perception%20Systems.pdf	Coming soon	/images/semLidarFuzz.png	https://github.com/less-lab-uva/semLidarFuzz
